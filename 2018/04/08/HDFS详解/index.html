<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        HDFS详解 - undefined
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> sometimes code， sometimes design </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar">
            <img src="/" />
        </div>
        <div class="name">
            <i>AirCloud</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>HOME</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>TAGS</span>
                </a>
            </li>
            <li >
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>ARCHIVES</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>ABOUT</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">search</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>
        <div class="index-about-mobile">
            <i>  </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        HDFS详解
    </div>

    <div class="post-meta">
        <span class="attr">Post：<span>2018-04-08 09:09:12</span></span>
        
        <span class="attr">Tags：/
        
        <a class="tag" href="/tags/#Hadoop,大数据" title="Hadoop,大数据">Hadoop,大数据</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">Visit：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <p>一、简介</p>
<ol>
<li><p>HDFS前言</p>
<p>设计思想：</p>
<pre><code>分而治之，将大文件、大批量文件，分布式存放在大量服务器上，以便于采取 分而治之的方式对海量数据进行运算分析；在大数据系统中作用：为各类分布式运算框架（如：mapreduce，spark，tez，……）提供数据存储服务
</code></pre><p>重点概念：文件切块，副本存放，元数据</p>
</li>
<li><p>HDFS的概念和特性</p>
<pre><code>首先，它是一个文件系统，用于存储文件，通过统一的命名空间——目录树来定位文件。其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色； 重要特性如下：
</code></pre></li>
</ol>
<ul>
<li>namenode是HDFS集群主节点，负责维护整个hdfs文件系统的目录树，以及每一个路径（文件）所对应的block块信息（block的id，及所在的datanode服务器） </li>
<li>datanode是HDFS集群从节点，每一个block都可以在多个datanode上存储多个副本（副本数量也可以通过参数设置dfs.replication）</li>
<li>HDFS中的文件在物理上是分块存储（block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x版本中是128M，老版本中是64M</li>
<li>HDFS文件系统会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs://namenode:port/dir-a/dir-b/dir-c/file.data目录结构及文件分块信息(元数据)的管理由namenode节点承担，文件的各个block的存储管理由datanode节点承担。</li>
<li>HDFS是设计成适应一次写入，多次读出的场景，且不支持文件的修改<br>(注：适合用来做数据分析，并不适合用来做网盘应用，因为，不便修改，延迟大，网络开销大，成本太高)</li>
</ul>
<p>二、体系结构</p>
<p>1、HDFS集群分为两大角色：NameNode、DataNode</p>
<ul>
<li>NameNode：管理文件系统的namespace，维护整个文件系统的文件目录树以及这些文件的索引目录，也就是管理整个文件系统的元数据。谢谢元数据信息以两种方式存储在本地文件系统中，是image和edits，NameNode会在系统启东市将这些信息载入内存。</li>
<li>DataNode：负责管理文件数据分块。通过心跳定时向NameNode发送所存储的文件块信息。</li>
</ul>
<p>2、写数据流程<br>        客户端要向HDFS写数据，首先要跟Namenode通信以确认可以写文件并获得接收文件block的Datanode，然后，客户端按顺序将文件逐个block传递给相应Datanode，并由接收到block的Datanode负责向其他Datanode复制block的副本。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fq4zp5vn0gj30ya0lwn2t.jpg" alt=""></p>
<pre><code>1. 根namenode通信请求上传文件，namenode检查目标文件是否已存在，父目录是否存在
2. namenode返回是否可以上传
3. client请求第一个 block该传输到哪些datanode服务器上
4. namenode返回3个datanode服务器ABC
5. client请求3台dn中的一台A上传数据（本质上是一个RPC调用，建立pipeline），A收到请求会继续调用B，然后B调用C，将真个pipeline建立完成，逐级返回客户端
6. client开始往A上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，A收到一个packet就会传给B，B传给C；A每传一个packet会放入一个应答队列等待应答
7. 当一个block传输完成之后，client再次请求namenode上传第二个block的服务器。
</code></pre><p>3、读数据流程<br>        客户端将要读取的文件路径发送给namenode，namenode获取文件的元信息（主要是block的存放位置信息）返回给客户端，客户端根据返回的信息找到相应datanode逐个获取文件的block并在客户端本地进行数据追加合并从而获得整个文件</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fq4zq29x7vj31540ju0wt.jpg" alt=""></p>
<pre><code>1. 跟namenode通信查询元数据，找到文件块所在的datanode服务器
2. 挑选一台datanode（就近原则，然后随机）服务器，请求建立socket流
3. datanode开始发送数据（从磁盘里面读取数据放入流，以packet为单位来做校验）
4. 客户端以packet为单位接收，现在本地缓存，然后写入目标文件
</code></pre><p>4、副本存放于读取策略<br>        机架感知策略：默认情况下，副本数量为3，hdfs的存放策略</p>
<pre><code>* 一个副本存放在本机架的节点上
* 一个副本存放在本机架的另一个节点上
* 一个副本放在不同的机架上
</code></pre><p>5、安全模式<br>        NameNode启动后进入安全模式，不会进行数据块的复制，NameNode检测DataNode上传的数据块信息中副本数量是否达到了最小副本数，当确认副本安全的数据块达到一定比例后，就退出安全模式。然后将没有达到指定副本数的数据块复制到其他DataNode节点上。</p>
<p>6、文件安全<br>        在另一个节点上同步运行一个ScondaryNameNode周期性的合并edits和image。</p>
<p>三、工作机制</p>
<p> 1、元数据存储机制</p>
<ul>
<li>内存中有一份完整的元数据：meta.data</li>
<li>磁盘中有一份“准完整”的元数据镜像：fsimage</li>
<li>日志文件edits<br>备注：用户对数据的更新修改等操作首先会记录到edits日志文件中，当用户的操作成功提交后，相应的元数据会更新到内存中的meta.data中。</li>
</ul>
<p>2、元数据的checkpoint<br>        每隔一段时间，SecondaryNameNode会将最新的edits日志文件和NameNode上最新的fsimage下载到本地磁盘中，并加载到内存进行合并，这个过程就是checkpoint。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fq4zr0braij30yk0iodkr.jpg" alt=""></p>
<p>3、DataNode工作机制<br>        Datanode工作职责：存储管理用户的文件块数据，定期向namenode汇报自身所持有的block信息（通过心跳信息上报），datanode进程死亡或者网络故障造成datanode无法与namenode通信，namenode不会立即把该节点判定为死亡，要经过一段时间，这段时间暂称作超时时长。HDFS默认的超时时长为10分钟+30秒。</p>

        
        <div id="comment-container">
        </div>
    </div>
</div>
    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = ""
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

</html>
